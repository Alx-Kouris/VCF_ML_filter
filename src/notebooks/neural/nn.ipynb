{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f44f1cd2-6f2b-42bc-b674-86fd378b47bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /home/kourisa/anaconda3/lib/python3.9/site-packages (1.5.1)\n",
      "Requirement already satisfied: torchviz in /home/kourisa/anaconda3/lib/python3.9/site-packages (0.0.3)\n",
      "Requirement already satisfied: torch in /home/kourisa/anaconda3/lib/python3.9/site-packages (from torchviz) (2.0.1)\n",
      "Requirement already satisfied: graphviz in /home/kourisa/anaconda3/lib/python3.9/site-packages (from torchviz) (0.20.3)\n",
      "Requirement already satisfied: filelock in /home/kourisa/anaconda3/lib/python3.9/site-packages (from torch->torchviz) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /home/kourisa/anaconda3/lib/python3.9/site-packages (from torch->torchviz) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/kourisa/anaconda3/lib/python3.9/site-packages (from torch->torchviz) (1.12)\n",
      "Requirement already satisfied: networkx in /home/kourisa/anaconda3/lib/python3.9/site-packages (from torch->torchviz) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/kourisa/anaconda3/lib/python3.9/site-packages (from torch->torchviz) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/kourisa/anaconda3/lib/python3.9/site-packages (from torch->torchviz) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/kourisa/anaconda3/lib/python3.9/site-packages (from torch->torchviz) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/kourisa/anaconda3/lib/python3.9/site-packages (from torch->torchviz) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/kourisa/anaconda3/lib/python3.9/site-packages (from torch->torchviz) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/kourisa/anaconda3/lib/python3.9/site-packages (from torch->torchviz) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/kourisa/anaconda3/lib/python3.9/site-packages (from torch->torchviz) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/kourisa/anaconda3/lib/python3.9/site-packages (from torch->torchviz) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/kourisa/anaconda3/lib/python3.9/site-packages (from torch->torchviz) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/kourisa/anaconda3/lib/python3.9/site-packages (from torch->torchviz) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/kourisa/anaconda3/lib/python3.9/site-packages (from torch->torchviz) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/kourisa/anaconda3/lib/python3.9/site-packages (from torch->torchviz) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/kourisa/anaconda3/lib/python3.9/site-packages (from torch->torchviz) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/kourisa/anaconda3/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->torchviz) (69.5.1)\n",
      "Requirement already satisfied: wheel in /home/kourisa/anaconda3/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->torchviz) (0.43.0)\n",
      "Requirement already satisfied: cmake in /home/kourisa/anaconda3/lib/python3.9/site-packages (from triton==2.0.0->torch->torchviz) (3.30.2)\n",
      "Requirement already satisfied: lit in /home/kourisa/anaconda3/lib/python3.9/site-packages (from triton==2.0.0->torch->torchviz) (18.1.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/kourisa/anaconda3/lib/python3.9/site-packages (from jinja2->torch->torchviz) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/kourisa/anaconda3/lib/python3.9/site-packages (from sympy->torch->torchviz) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary\n",
    "!pip install torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaca3b94-82da-4530-b7a4-9a8fc42e664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, precision_recall_curve\n",
    ")\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "from torchsummary import summary\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c811fe2f-2731-4f78-b98a-b372108a774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load and preprocess data ===\n",
    "df = pd.read_csv(\"vcf_feature_vectors.csv\")\n",
    "df[\"GOLDEN\"] = df[\"GOLDEN\"].fillna(0).astype(int)\n",
    "\n",
    "non_feature_cols = [\"CHROM\", \"POS\", \"REF\", \"ALT\", \"GOLDEN\"]\n",
    "features = df.drop(columns=non_feature_cols).columns.tolist()\n",
    "X = df[features].values.astype(np.float32)\n",
    "y = df[\"GOLDEN\"].values.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da95ea3f-b46f-4db4-a713-131639186db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Define model ===\n",
    "class FeedforwardNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33f95197-b740-4860-954e-15bab780ace3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [-1, 64]             768\n",
      "       BatchNorm1d-2                   [-1, 64]             128\n",
      "              ReLU-3                   [-1, 64]               0\n",
      "           Dropout-4                   [-1, 64]               0\n",
      "            Linear-5                   [-1, 32]           2,080\n",
      "       BatchNorm1d-6                   [-1, 32]              64\n",
      "              ReLU-7                   [-1, 32]               0\n",
      "           Dropout-8                   [-1, 32]               0\n",
      "            Linear-9                    [-1, 1]              33\n",
      "          Sigmoid-10                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 3,073\n",
      "Trainable params: 3,073\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.01\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model_architecture.png'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Visualize architecture (summary and torchviz) ===\n",
    "dummy_input_dim = X.shape[1]  # assuming X already defined\n",
    "model_viz = FeedforwardNet(input_dim=dummy_input_dim)\n",
    "summary(model_viz, input_size=(dummy_input_dim,))\n",
    "\n",
    "dummy_input = torch.randn(1, dummy_input_dim)\n",
    "model_viz.eval()\n",
    "make_dot(model_viz(dummy_input), params=dict(model_viz.named_parameters())).render(\"model_architecture\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38e5758b-0987-4c9c-b63c-a69fd8825027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 1/30: 100%|█████████████████████████████████████████| 1041/1041 [00:07<00:00, 146.89batch/s, loss=0.0992]\n",
      "Fold 1 Epoch 2/30: 100%|█████████████████████████████████████████| 1041/1041 [00:09<00:00, 110.62batch/s, loss=0.0429]\n",
      "Fold 1 Epoch 3/30: 100%|█████████████████████████████████████████| 1041/1041 [00:08<00:00, 123.90batch/s, loss=0.0404]\n",
      "Fold 1 Epoch 4/30: 100%|█████████████████████████████████████████| 1041/1041 [00:08<00:00, 128.96batch/s, loss=0.0384]\n",
      "Fold 1 Epoch 5/30: 100%|█████████████████████████████████████████| 1041/1041 [00:09<00:00, 115.61batch/s, loss=0.0375]\n",
      "Fold 1 Epoch 6/30: 100%|█████████████████████████████████████████| 1041/1041 [00:09<00:00, 111.31batch/s, loss=0.0368]\n",
      "Fold 1 Epoch 7/30: 100%|█████████████████████████████████████████| 1041/1041 [00:09<00:00, 114.99batch/s, loss=0.0367]\n",
      "Fold 1 Epoch 8/30: 100%|██████████████████████████████████████████| 1041/1041 [00:07<00:00, 132.16batch/s, loss=0.036]\n",
      "Fold 1 Epoch 9/30: 100%|█████████████████████████████████████████| 1041/1041 [00:08<00:00, 124.61batch/s, loss=0.0361]\n",
      "Fold 1 Epoch 10/30: 100%|████████████████████████████████████████| 1041/1041 [00:10<00:00, 101.18batch/s, loss=0.0354]\n",
      "Fold 1 Epoch 11/30: 100%|█████████████████████████████████████████| 1041/1041 [00:09<00:00, 108.41batch/s, loss=0.035]\n",
      "Fold 1 Epoch 12/30: 100%|████████████████████████████████████████| 1041/1041 [00:09<00:00, 115.31batch/s, loss=0.0354]\n",
      "Fold 1 Epoch 13/30: 100%|████████████████████████████████████████| 1041/1041 [00:09<00:00, 106.52batch/s, loss=0.0352]\n",
      "Fold 1 Epoch 14/30: 100%|████████████████████████████████████████| 1041/1041 [00:09<00:00, 109.64batch/s, loss=0.0346]\n",
      "Fold 1 Epoch 15/30: 100%|████████████████████████████████████████| 1041/1041 [00:10<00:00, 103.13batch/s, loss=0.0346]\n",
      "Fold 1 Epoch 16/30: 100%|████████████████████████████████████████| 1041/1041 [00:09<00:00, 115.59batch/s, loss=0.0344]\n",
      "Fold 1 Epoch 17/30: 100%|█████████████████████████████████████████| 1041/1041 [00:09<00:00, 114.74batch/s, loss=0.034]\n",
      "Fold 1 Epoch 18/30: 100%|█████████████████████████████████████████| 1041/1041 [00:10<00:00, 95.47batch/s, loss=0.0336]\n",
      "Fold 1 Epoch 19/30: 100%|█████████████████████████████████████████| 1041/1041 [00:10<00:00, 101.81batch/s, loss=0.034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 1/30: 100%|██████████████████████████████████████████| 1041/1041 [00:10<00:00, 102.85batch/s, loss=0.107]\n",
      "Fold 2 Epoch 2/30: 100%|█████████████████████████████████████████| 1041/1041 [00:08<00:00, 117.98batch/s, loss=0.0441]\n",
      "Fold 2 Epoch 3/30: 100%|███████████████████████████████████████████| 1041/1041 [00:12<00:00, 81.09batch/s, loss=0.042]\n",
      "Fold 2 Epoch 4/30: 100%|█████████████████████████████████████████| 1041/1041 [00:09<00:00, 114.51batch/s, loss=0.0395]\n",
      "Fold 2 Epoch 5/30: 100%|█████████████████████████████████████████| 1041/1041 [00:09<00:00, 112.05batch/s, loss=0.0391]\n",
      "Fold 2 Epoch 6/30: 100%|█████████████████████████████████████████| 1041/1041 [00:10<00:00, 102.08batch/s, loss=0.0379]\n",
      "Fold 2 Epoch 7/30: 100%|█████████████████████████████████████████| 1041/1041 [00:09<00:00, 110.00batch/s, loss=0.0376]\n",
      "Fold 2 Epoch 8/30: 100%|██████████████████████████████████████████| 1041/1041 [00:10<00:00, 99.55batch/s, loss=0.0374]\n",
      "Fold 2 Epoch 9/30: 100%|█████████████████████████████████████████| 1041/1041 [00:09<00:00, 108.63batch/s, loss=0.0367]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Early stopping at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 1/30: 100%|█████████████████████████████████████████| 1041/1041 [00:08<00:00, 127.92batch/s, loss=0.0925]\n",
      "Fold 3 Epoch 2/30: 100%|█████████████████████████████████████████| 1041/1041 [00:08<00:00, 128.87batch/s, loss=0.0429]\n",
      "Fold 3 Epoch 3/30: 100%|█████████████████████████████████████████| 1041/1041 [00:08<00:00, 121.81batch/s, loss=0.0403]\n",
      "Fold 3 Epoch 4/30: 100%|█████████████████████████████████████████| 1041/1041 [00:08<00:00, 128.97batch/s, loss=0.0387]\n",
      "Fold 3 Epoch 5/30: 100%|█████████████████████████████████████████| 1041/1041 [00:09<00:00, 105.09batch/s, loss=0.0374]\n",
      "Fold 3 Epoch 6/30: 100%|█████████████████████████████████████████| 1041/1041 [00:10<00:00, 102.40batch/s, loss=0.0372]\n",
      "Fold 3 Epoch 7/30: 100%|█████████████████████████████████████████| 1041/1041 [00:08<00:00, 124.31batch/s, loss=0.0365]\n",
      "Fold 3 Epoch 8/30: 100%|█████████████████████████████████████████| 1041/1041 [00:09<00:00, 109.34batch/s, loss=0.0361]\n",
      "Fold 3 Epoch 9/30: 100%|█████████████████████████████████████████| 1041/1041 [00:09<00:00, 110.03batch/s, loss=0.0357]\n",
      "Fold 3 Epoch 10/30: 100%|████████████████████████████████████████| 1041/1041 [00:09<00:00, 110.40batch/s, loss=0.0355]\n",
      "Fold 3 Epoch 11/30: 100%|█████████████████████████████████████████| 1041/1041 [00:09<00:00, 106.27batch/s, loss=0.035]\n",
      "Fold 3 Epoch 12/30: 100%|█████████████████████████████████████████| 1041/1041 [00:11<00:00, 92.99batch/s, loss=0.0353]\n",
      "Fold 3 Epoch 13/30: 100%|████████████████████████████████████████| 1041/1041 [00:08<00:00, 129.18batch/s, loss=0.0344]\n",
      "Fold 3 Epoch 14/30: 100%|████████████████████████████████████████| 1041/1041 [00:07<00:00, 131.42batch/s, loss=0.0345]\n",
      "Fold 3 Epoch 15/30: 100%|████████████████████████████████████████| 1041/1041 [00:08<00:00, 122.72batch/s, loss=0.0347]\n",
      "Fold 3 Epoch 16/30: 100%|████████████████████████████████████████| 1041/1041 [00:09<00:00, 109.18batch/s, loss=0.0343]\n",
      "Fold 3 Epoch 17/30: 100%|████████████████████████████████████████| 1041/1041 [00:09<00:00, 114.49batch/s, loss=0.0337]\n",
      "Fold 3 Epoch 18/30: 100%|█████████████████████████████████████████| 1041/1041 [00:15<00:00, 66.23batch/s, loss=0.0335]\n",
      "Fold 3 Epoch 19/30: 100%|█████████████████████████████████████████| 1041/1041 [00:16<00:00, 63.62batch/s, loss=0.0336]\n",
      "Fold 3 Epoch 20/30: 100%|█████████████████████████████████████████| 1041/1041 [00:14<00:00, 69.93batch/s, loss=0.0331]\n",
      "Fold 3 Epoch 21/30: 100%|████████████████████████████████████████| 1041/1041 [00:09<00:00, 107.28batch/s, loss=0.0332]\n",
      "Fold 3 Epoch 22/30: 100%|█████████████████████████████████████████| 1041/1041 [00:11<00:00, 90.12batch/s, loss=0.0331]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 1/30: 100%|██████████████████████████████████████████| 1041/1041 [00:09<00:00, 111.16batch/s, loss=0.119]\n",
      "Fold 4 Epoch 2/30: 100%|█████████████████████████████████████████| 1041/1041 [00:07<00:00, 144.59batch/s, loss=0.0441]\n",
      "Fold 4 Epoch 3/30: 100%|█████████████████████████████████████████| 1041/1041 [00:08<00:00, 127.63batch/s, loss=0.0419]\n",
      "Fold 4 Epoch 4/30: 100%|█████████████████████████████████████████| 1041/1041 [00:08<00:00, 123.54batch/s, loss=0.0408]\n",
      "Fold 4 Epoch 5/30: 100%|█████████████████████████████████████████| 1041/1041 [00:09<00:00, 112.13batch/s, loss=0.0387]\n",
      "Fold 4 Epoch 6/30: 100%|█████████████████████████████████████████| 1041/1041 [00:08<00:00, 118.19batch/s, loss=0.0378]\n",
      "Fold 4 Epoch 7/30: 100%|█████████████████████████████████████████| 1041/1041 [00:08<00:00, 124.08batch/s, loss=0.0375]\n",
      "Fold 4 Epoch 8/30: 100%|█████████████████████████████████████████| 1041/1041 [00:08<00:00, 129.19batch/s, loss=0.0371]\n",
      "Fold 4 Epoch 9/30: 100%|█████████████████████████████████████████| 1041/1041 [00:08<00:00, 121.42batch/s, loss=0.0361]\n",
      "Fold 4 Epoch 10/30: 100%|█████████████████████████████████████████| 1041/1041 [00:07<00:00, 133.53batch/s, loss=0.036]\n",
      "Fold 4 Epoch 11/30: 100%|████████████████████████████████████████| 1041/1041 [00:07<00:00, 138.06batch/s, loss=0.0357]\n",
      "Fold 4 Epoch 12/30: 100%|████████████████████████████████████████| 1041/1041 [00:09<00:00, 107.82batch/s, loss=0.0356]\n",
      "Fold 4 Epoch 13/30: 100%|████████████████████████████████████████| 1041/1041 [00:09<00:00, 106.78batch/s, loss=0.0348]\n",
      "Fold 4 Epoch 14/30: 100%|████████████████████████████████████████| 1041/1041 [00:08<00:00, 122.20batch/s, loss=0.0345]\n",
      "Fold 4 Epoch 15/30: 100%|█████████████████████████████████████████| 1041/1041 [00:12<00:00, 82.21batch/s, loss=0.0344]\n",
      "Fold 4 Epoch 16/30: 100%|████████████████████████████████████████| 1041/1041 [00:09<00:00, 110.71batch/s, loss=0.0345]\n",
      "Fold 4 Epoch 17/30: 100%|█████████████████████████████████████████| 1041/1041 [00:12<00:00, 86.39batch/s, loss=0.0346]\n",
      "Fold 4 Epoch 18/30: 100%|█████████████████████████████████████████| 1041/1041 [00:10<00:00, 97.38batch/s, loss=0.0344]\n",
      "Fold 4 Epoch 19/30: 100%|████████████████████████████████████████| 1041/1041 [00:08<00:00, 122.09batch/s, loss=0.0336]\n",
      "Fold 4 Epoch 20/30: 100%|████████████████████████████████████████| 1041/1041 [00:08<00:00, 125.19batch/s, loss=0.0336]\n",
      "Fold 4 Epoch 21/30: 100%|████████████████████████████████████████| 1041/1041 [00:08<00:00, 123.81batch/s, loss=0.0334]\n",
      "Fold 4 Epoch 22/30: 100%|████████████████████████████████████████| 1041/1041 [00:07<00:00, 135.59batch/s, loss=0.0333]\n",
      "Fold 4 Epoch 23/30: 100%|█████████████████████████████████████████| 1041/1041 [00:12<00:00, 82.74batch/s, loss=0.0336]\n",
      "Fold 4 Epoch 24/30: 100%|█████████████████████████████████████████| 1041/1041 [00:14<00:00, 71.60batch/s, loss=0.0331]\n",
      "Fold 4 Epoch 25/30: 100%|██████████████████████████████████████████| 1041/1041 [00:10<00:00, 98.59batch/s, loss=0.033]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Early stopping at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 1/30: 100%|████████████████████████████████████████████| 1041/1041 [00:14<00:00, 71.56batch/s, loss=0.12]\n",
      "Fold 5 Epoch 2/30: 100%|██████████████████████████████████████████| 1041/1041 [00:13<00:00, 76.55batch/s, loss=0.0447]\n",
      "Fold 5 Epoch 3/30: 100%|██████████████████████████████████████████| 1041/1041 [00:11<00:00, 90.69batch/s, loss=0.0415]\n",
      "Fold 5 Epoch 4/30: 100%|██████████████████████████████████████████| 1041/1041 [00:14<00:00, 70.83batch/s, loss=0.0395]\n",
      "Fold 5 Epoch 5/30: 100%|█████████████████████████████████████████| 1041/1041 [00:09<00:00, 105.92batch/s, loss=0.0387]\n",
      "Fold 5 Epoch 6/30: 100%|█████████████████████████████████████████| 1041/1041 [00:09<00:00, 105.73batch/s, loss=0.0378]\n",
      "Fold 5 Epoch 7/30: 100%|██████████████████████████████████████████| 1041/1041 [00:08<00:00, 116.89batch/s, loss=0.037]\n",
      "Fold 5 Epoch 8/30: 100%|█████████████████████████████████████████| 1041/1041 [00:09<00:00, 107.66batch/s, loss=0.0368]\n",
      "Fold 5 Epoch 9/30: 100%|█████████████████████████████████████████| 1041/1041 [00:09<00:00, 105.99batch/s, loss=0.0363]\n",
      "Fold 5 Epoch 10/30: 100%|█████████████████████████████████████████| 1041/1041 [00:10<00:00, 98.82batch/s, loss=0.0357]\n",
      "Fold 5 Epoch 11/30: 100%|████████████████████████████████████████| 1041/1041 [00:08<00:00, 121.90batch/s, loss=0.0359]\n",
      "Fold 5 Epoch 12/30: 100%|█████████████████████████████████████████| 1041/1041 [00:10<00:00, 97.07batch/s, loss=0.0354]\n",
      "Fold 5 Epoch 13/30: 100%|████████████████████████████████████████| 1041/1041 [00:09<00:00, 110.85batch/s, loss=0.0351]\n",
      "Fold 5 Epoch 14/30: 100%|████████████████████████████████████████| 1041/1041 [00:08<00:00, 122.79batch/s, loss=0.0349]\n",
      "Fold 5 Epoch 15/30: 100%|█████████████████████████████████████████| 1041/1041 [00:08<00:00, 125.56batch/s, loss=0.035]\n",
      "Fold 5 Epoch 16/30: 100%|████████████████████████████████████████| 1041/1041 [00:08<00:00, 118.88batch/s, loss=0.0349]\n",
      "Fold 5 Epoch 17/30: 100%|████████████████████████████████████████| 1041/1041 [00:10<00:00, 100.37batch/s, loss=0.0344]\n",
      "Fold 5 Epoch 18/30: 100%|████████████████████████████████████████| 1041/1041 [00:10<00:00, 103.82batch/s, loss=0.0342]\n",
      "Fold 5 Epoch 19/30: 100%|████████████████████████████████████████| 1041/1041 [00:09<00:00, 112.90batch/s, loss=0.0344]\n",
      "Fold 5 Epoch 20/30: 100%|████████████████████████████████████████| 1041/1041 [00:07<00:00, 145.37batch/s, loss=0.0343]\n",
      "Fold 5 Epoch 21/30: 100%|████████████████████████████████████████| 1041/1041 [00:07<00:00, 135.31batch/s, loss=0.0341]\n",
      "Fold 5 Epoch 22/30: 100%|████████████████████████████████████████| 1041/1041 [00:08<00:00, 117.99batch/s, loss=0.0339]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Early stopping at epoch 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>Best Threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.987781</td>\n",
       "      <td>0.532609</td>\n",
       "      <td>0.454756</td>\n",
       "      <td>0.490613</td>\n",
       "      <td>0.964834</td>\n",
       "      <td>0.208299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.988891</td>\n",
       "      <td>0.593168</td>\n",
       "      <td>0.444186</td>\n",
       "      <td>0.507979</td>\n",
       "      <td>0.965854</td>\n",
       "      <td>0.251655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.987000</td>\n",
       "      <td>0.496437</td>\n",
       "      <td>0.486047</td>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.965279</td>\n",
       "      <td>0.190984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.988711</td>\n",
       "      <td>0.580838</td>\n",
       "      <td>0.451163</td>\n",
       "      <td>0.507853</td>\n",
       "      <td>0.968028</td>\n",
       "      <td>0.232157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.990332</td>\n",
       "      <td>0.698182</td>\n",
       "      <td>0.445476</td>\n",
       "      <td>0.543909</td>\n",
       "      <td>0.970826</td>\n",
       "      <td>0.323058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.988543</td>\n",
       "      <td>0.580247</td>\n",
       "      <td>0.456325</td>\n",
       "      <td>0.508308</td>\n",
       "      <td>0.966964</td>\n",
       "      <td>0.241230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fold  Accuracy  Precision    Recall        F1   ROC AUC  Best Threshold\n",
       "0      1.0  0.987781   0.532609  0.454756  0.490613  0.964834        0.208299\n",
       "1      2.0  0.988891   0.593168  0.444186  0.507979  0.965854        0.251655\n",
       "2      3.0  0.987000   0.496437  0.486047  0.491187  0.965279        0.190984\n",
       "3      4.0  0.988711   0.580838  0.451163  0.507853  0.968028        0.232157\n",
       "4      5.0  0.990332   0.698182  0.445476  0.543909  0.970826        0.323058\n",
       "Mean   3.0  0.988543   0.580247  0.456325  0.508308  0.966964        0.241230"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Cross-validation ===\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "metrics_per_fold = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "    model = FeedforwardNet(input_dim=X.shape[1])\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    train_loader = DataLoader(TensorDataset(torch.tensor(X_train), torch.tensor(y_train)), batch_size=128, shuffle=True)\n",
    "\n",
    "    best_f1 = -1\n",
    "    epochs_no_improve = 0\n",
    "    patience = 5\n",
    "    best_model_state = None\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(30):\n",
    "        running_loss = 0.0\n",
    "        with tqdm(train_loader, desc=f\"Fold {fold+1} Epoch {epoch+1}/30\", unit=\"batch\") as tepoch:\n",
    "            for xb, yb in tepoch:\n",
    "                preds = model(xb).squeeze()\n",
    "                loss = criterion(preds, yb.float())\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                tepoch.set_postfix(loss=running_loss / (tepoch.n + 1))\n",
    "\n",
    "        # Evaluate for early stopping\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_probs = model(torch.tensor(X_val)).squeeze().numpy()\n",
    "        val_preds = (val_probs >= 0.5).astype(int)\n",
    "        val_f1 = f1_score(y_val, val_preds)\n",
    "\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = model.state_dict()\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"🔁 Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    # Load best weights if available\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    else:\n",
    "        print(f\"⚠️ Warning: No improvement found during training for fold {fold + 1}. Skipping weight restoration.\")\n",
    "\n",
    "\n",
    "    # Final evaluation with tuned threshold\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        probas = model(torch.tensor(X_val)).squeeze().numpy()\n",
    "\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_val, probas)\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    best_thresh = thresholds[best_idx]\n",
    "    preds = (probas >= best_thresh).astype(int)\n",
    "\n",
    "    metrics_per_fold.append({\n",
    "        \"Fold\": fold + 1,\n",
    "        \"Accuracy\": accuracy_score(y_val, preds),\n",
    "        \"Precision\": precision_score(y_val, preds),\n",
    "        \"Recall\": recall_score(y_val, preds),\n",
    "        \"F1\": f1_score(y_val, preds),\n",
    "        \"ROC AUC\": roc_auc_score(y_val, probas),\n",
    "        \"Best Threshold\": best_thresh\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(metrics_per_fold)\n",
    "results_df.loc[\"Mean\"] = results_df.mean(numeric_only=True)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e60ff255-7b03-422d-9ec0-394e78629df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save average threshold\n",
    "avg_best_thresh = results_df[\"Best Threshold\"].dropna().mean()\n",
    "\n",
    "# Save model metadata\n",
    "metadata = {\n",
    "    \"features\": features,  # or top_features if you're using selection\n",
    "    \"threshold\": float(avg_best_thresh)\n",
    "}\n",
    "with open(\"model_metadata.json\", \"w\") as f:\n",
    "    json.dump(metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5a9c9d8-21bc-40e3-bdd0-3f0943c35130",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 1/30: 100%|█████████████████████████████████████| 1302/1302 [00:14<00:00, 87.40batch/s, loss=0.0952]\n",
      "Final Model Epoch 2/30: 100%|████████████████████████████████████| 1302/1302 [00:11<00:00, 113.41batch/s, loss=0.0482]\n",
      "Final Model Epoch 3/30: 100%|████████████████████████████████████| 1302/1302 [00:08<00:00, 154.36batch/s, loss=0.0466]\n",
      "Final Model Epoch 4/30: 100%|████████████████████████████████████| 1302/1302 [00:07<00:00, 175.84batch/s, loss=0.0453]\n",
      "Final Model Epoch 5/30: 100%|████████████████████████████████████| 1302/1302 [00:07<00:00, 174.95batch/s, loss=0.0447]\n",
      "Final Model Epoch 6/30: 100%|████████████████████████████████████| 1302/1302 [00:07<00:00, 175.66batch/s, loss=0.0441]\n",
      "Final Model Epoch 7/30: 100%|████████████████████████████████████| 1302/1302 [00:07<00:00, 164.34batch/s, loss=0.0438]\n",
      "Final Model Epoch 8/30: 100%|████████████████████████████████████| 1302/1302 [00:08<00:00, 159.64batch/s, loss=0.0438]\n",
      "Final Model Epoch 9/30: 100%|████████████████████████████████████| 1302/1302 [00:08<00:00, 150.75batch/s, loss=0.0433]\n",
      "Final Model Epoch 10/30: 100%|███████████████████████████████████| 1302/1302 [00:09<00:00, 136.21batch/s, loss=0.0424]\n",
      "Final Model Epoch 11/30: 100%|███████████████████████████████████| 1302/1302 [00:08<00:00, 155.60batch/s, loss=0.0425]\n",
      "Final Model Epoch 12/30: 100%|███████████████████████████████████| 1302/1302 [00:08<00:00, 161.35batch/s, loss=0.0416]\n",
      "Final Model Epoch 13/30: 100%|███████████████████████████████████| 1302/1302 [00:08<00:00, 150.64batch/s, loss=0.0416]\n",
      "Final Model Epoch 14/30: 100%|███████████████████████████████████| 1302/1302 [00:09<00:00, 138.28batch/s, loss=0.0422]\n",
      "Final Model Epoch 15/30: 100%|███████████████████████████████████| 1302/1302 [00:11<00:00, 114.32batch/s, loss=0.0418]\n",
      "Final Model Epoch 16/30: 100%|███████████████████████████████████| 1302/1302 [00:09<00:00, 135.07batch/s, loss=0.0416]\n",
      "Final Model Epoch 17/30: 100%|███████████████████████████████████| 1302/1302 [00:09<00:00, 140.97batch/s, loss=0.0413]\n",
      "Final Model Epoch 18/30: 100%|███████████████████████████████████| 1302/1302 [00:09<00:00, 142.68batch/s, loss=0.0415]\n",
      "Final Model Epoch 19/30: 100%|████████████████████████████████████| 1302/1302 [00:10<00:00, 124.21batch/s, loss=0.041]\n",
      "Final Model Epoch 20/30: 100%|███████████████████████████████████| 1302/1302 [00:12<00:00, 102.75batch/s, loss=0.0413]\n",
      "Final Model Epoch 21/30: 100%|█████████████████████████████████████| 1302/1302 [00:14<00:00, 90.04batch/s, loss=0.041]\n",
      "Final Model Epoch 22/30: 100%|████████████████████████████████████| 1302/1302 [00:17<00:00, 73.01batch/s, loss=0.0408]\n",
      "Final Model Epoch 23/30: 100%|████████████████████████████████████| 1302/1302 [00:14<00:00, 90.69batch/s, loss=0.0414]\n",
      "Final Model Epoch 24/30: 100%|████████████████████████████████████| 1302/1302 [00:15<00:00, 84.31batch/s, loss=0.0406]\n",
      "Final Model Epoch 25/30: 100%|████████████████████████████████████| 1302/1302 [00:24<00:00, 53.97batch/s, loss=0.0402]\n",
      "Final Model Epoch 26/30: 100%|████████████████████████████████████| 1302/1302 [00:20<00:00, 64.48batch/s, loss=0.0407]\n",
      "Final Model Epoch 27/30: 100%|████████████████████████████████████| 1302/1302 [00:13<00:00, 95.82batch/s, loss=0.0404]\n",
      "Final Model Epoch 28/30: 100%|████████████████████████████████████| 1302/1302 [00:14<00:00, 89.47batch/s, loss=0.0403]\n",
      "Final Model Epoch 29/30: 100%|████████████████████████████████████| 1302/1302 [00:14<00:00, 89.32batch/s, loss=0.0408]\n",
      "Final Model Epoch 30/30: 100%|████████████████████████████████████| 1302/1302 [00:15<00:00, 82.53batch/s, loss=0.0407]\n"
     ]
    }
   ],
   "source": [
    "# === Final training ===\n",
    "final_model = FeedforwardNet(input_dim=X.shape[1])\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(final_model.parameters(), lr=0.001)\n",
    "loader = DataLoader(TensorDataset(torch.tensor(X), torch.tensor(y)), batch_size=128, shuffle=True)\n",
    "\n",
    "final_model.train()\n",
    "for epoch in range(30):\n",
    "    running_loss = 0.0\n",
    "    with tqdm(loader, desc=f\"Final Model Epoch {epoch+1}/30\", unit=\"batch\") as tepoch:\n",
    "        for xb, yb in tepoch:\n",
    "            preds = final_model(xb).squeeze()\n",
    "            loss = criterion(preds, yb.float())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            tepoch.set_postfix(loss=running_loss / (tepoch.n + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ba18a5e-2b7b-4e3a-9476-6b92369a979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Save model ===\n",
    "torch.save(final_model.state_dict(), \"final_nn_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb01dc3-0c41-421b-823e-b79038ac9092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
